{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Univariate, Bivariate, and Multivariate Analysis\n",
        "\n",
        "This notebook performs:\n",
        "1. **Univariate Analysis** - Analysis of individual variables\n",
        "2. **Bivariate Analysis** - Analysis of relationships between two variables  \n",
        "3. **Multivariate Analysis** - Analysis of relationships among multiple variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load data\n",
        "data_path = Path('../../data/fraud_data.csv')\n",
        "df = pd.read_csv(data_path)\n",
        "print(f\"Data loaded: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Univariate Analysis\n",
        "\n",
        "Univariate analysis examines individual variables to understand their distribution, central tendencies, and variability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate analysis for TransactionAmt\n",
        "if 'TransactionAmt' in df.columns:\n",
        "    print(\"Univariate Analysis: TransactionAmt\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"Mean: {df['TransactionAmt'].mean():.2f}\")\n",
        "    print(f\"Median: {df['TransactionAmt'].median():.2f}\")\n",
        "    print(f\"Mode: {df['TransactionAmt'].mode().values[0] if len(df['TransactionAmt'].mode()) > 0 else 'N/A'}\")\n",
        "    print(f\"Std: {df['TransactionAmt'].std():.2f}\")\n",
        "    print(f\"Variance: {df['TransactionAmt'].var():.2f}\")\n",
        "    print(f\"Skewness: {df['TransactionAmt'].skew():.4f}\")\n",
        "    print(f\"Kurtosis: {df['TransactionAmt'].kurtosis():.4f}\")\n",
        "    print(f\"Min: {df['TransactionAmt'].min():.2f}\")\n",
        "    print(f\"Max: {df['TransactionAmt'].max():.2f}\")\n",
        "    print(f\"25th percentile: {df['TransactionAmt'].quantile(0.25):.2f}\")\n",
        "    print(f\"75th percentile: {df['TransactionAmt'].quantile(0.75):.2f}\")\n",
        "    print(f\"IQR: {df['TransactionAmt'].quantile(0.75) - df['TransactionAmt'].quantile(0.25):.2f}\")\n",
        "    \n",
        "    # Comprehensive visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    \n",
        "    # Histogram\n",
        "    axes[0, 0].hist(df['TransactionAmt'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    axes[0, 0].set_title('Histogram', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Transaction Amount')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].axvline(df['TransactionAmt'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"TransactionAmt\"].mean():.2f}')\n",
        "    axes[0, 0].axvline(df['TransactionAmt'].median(), color='green', linestyle='--', label=f'Median: {df[\"TransactionAmt\"].median():.2f}')\n",
        "    axes[0, 0].legend()\n",
        "    \n",
        "    # Box plot\n",
        "    axes[0, 1].boxplot(df['TransactionAmt'], vert=True)\n",
        "    axes[0, 1].set_title('Box Plot', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Transaction Amount')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Q-Q Plot\n",
        "    stats.probplot(df['TransactionAmt'], dist=\"norm\", plot=axes[0, 2])\n",
        "    axes[0, 2].set_title('Q-Q Plot (Normal Distribution)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Log transformation\n",
        "    log_trans_amt = np.log1p(df['TransactionAmt'])\n",
        "    axes[1, 0].hist(log_trans_amt, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "    axes[1, 0].set_title('Log-Transformed Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Log(Transaction Amount + 1)')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    \n",
        "    # Density plot\n",
        "    df['TransactionAmt'].plot.density(ax=axes[1, 1], color='purple')\n",
        "    axes[1, 1].set_title('Density Plot', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Transaction Amount')\n",
        "    axes[1, 1].set_ylabel('Density')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Violin plot (by fraud status if available)\n",
        "    if 'isFraud' in df.columns:\n",
        "        fraud_data = [df[df['isFraud']==0]['TransactionAmt'], df[df['isFraud']==1]['TransactionAmt']]\n",
        "        axes[1, 2].violinplot(fraud_data, positions=[0, 1], showmeans=True)\n",
        "        axes[1, 2].set_xticks([0, 1])\n",
        "        axes[1, 2].set_xticklabels(['Legitimate', 'Fraud'])\n",
        "        axes[1, 2].set_title('Transaction Amount by Fraud Status', fontsize=12, fontweight='bold')\n",
        "        axes[1, 2].set_ylabel('Transaction Amount')\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 2].text(0.5, 0.5, 'Fraud status not available', ha='center', va='center', transform=axes[1, 2].transAxes)\n",
        "        axes[1, 2].set_title('Transaction Amount by Fraud Status', fontsize=12, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/univariate_transactionamt.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Normality test\n",
        "    sample_size = min(5000, len(df))\n",
        "    sample_data = df['TransactionAmt'].sample(sample_size, random_state=42)\n",
        "    _, p_value = stats.normaltest(sample_data)\n",
        "    print(f\"\\nNormality Test (D'Agostino's test):\")\n",
        "    print(f\"  p-value: {p_value:.6f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(f\"  Result: Distribution is NOT normal (p < 0.05)\")\n",
        "    else:\n",
        "        print(f\"  Result: Distribution appears normal (p >= 0.05)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate analysis for multiple numerical features\n",
        "print(\"\\nUnivariate Analysis: Multiple Numerical Features\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select key numerical features\n",
        "numerical_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'dist2']\n",
        "numerical_features = [f for f in numerical_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "if len(numerical_features) > 0:\n",
        "    # Create summary statistics\n",
        "    univariate_summary = pd.DataFrame({\n",
        "        'Mean': df[numerical_features].mean(),\n",
        "        'Median': df[numerical_features].median(),\n",
        "        'Std': df[numerical_features].std(),\n",
        "        'Min': df[numerical_features].min(),\n",
        "        'Max': df[numerical_features].max(),\n",
        "        'Skewness': df[numerical_features].skew(),\n",
        "        'Kurtosis': df[numerical_features].kurtosis(),\n",
        "        'Missing_Count': df[numerical_features].isnull().sum(),\n",
        "        'Missing_Percentage': (df[numerical_features].isnull().sum() / len(df)) * 100\n",
        "    })\n",
        "    \n",
        "    print(\"\\nUnivariate Summary Statistics:\")\n",
        "    display(univariate_summary.round(4))\n",
        "    \n",
        "    # Visualize distributions for top features\n",
        "    n_features = min(6, len(numerical_features))\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, feature in enumerate(numerical_features[:n_features]):\n",
        "        axes[i].hist(df[feature].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
        "        axes[i].set_title(f'{feature} Distribution', fontsize=11, fontweight='bold')\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(n_features, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/univariate_multiple_features.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate analysis for categorical features\n",
        "print(\"\\nUnivariate Analysis: Categorical Features\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "categorical_features = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'DeviceType']\n",
        "categorical_features = [f for f in categorical_features if f in df.columns]\n",
        "\n",
        "if len(categorical_features) > 0:\n",
        "    for feature in categorical_features[:3]:  # Analyze first 3 categorical features\n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(\"-\" * 40)\n",
        "        value_counts = df[feature].value_counts()\n",
        "        print(f\"Unique values: {df[feature].nunique()}\")\n",
        "        print(f\"Most frequent value: {value_counts.index[0]} ({value_counts.values[0]} occurrences)\")\n",
        "        print(f\"\\nTop 10 values:\")\n",
        "        display(value_counts.head(10))\n",
        "        \n",
        "        # Visualize\n",
        "        if df[feature].nunique() <= 20:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            value_counts.head(10).plot(kind='bar', color='steelblue')\n",
        "            plt.title(f'{feature} Distribution (Top 10)', fontsize=12, fontweight='bold')\n",
        "            plt.xlabel(feature)\n",
        "            plt.ylabel('Count')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'../../outputs/figures/univariate_{feature}.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Bivariate Analysis\n",
        "\n",
        "Bivariate analysis examines the relationship between two variables to identify patterns, correlations, and associations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bivariate: TransactionAmt vs isFraud\n",
        "if 'TransactionAmt' in df.columns and 'isFraud' in df.columns:\n",
        "    print(\"Bivariate Analysis: TransactionAmt vs isFraud\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Statistical summary\n",
        "    print(\"\\nStatistical Summary by Fraud Status:\")\n",
        "    summary = df.groupby('isFraud')['TransactionAmt'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "    summary.columns = ['Count', 'Mean', 'Median', 'Std', 'Min', 'Max']\n",
        "    display(summary)\n",
        "    \n",
        "    # Correlation\n",
        "    corr = df[['TransactionAmt', 'isFraud']].corr().iloc[0, 1]\n",
        "    print(f\"\\nCorrelation coefficient: {corr:.4f}\")\n",
        "    \n",
        "    # Statistical test\n",
        "    from scipy.stats import mannwhitneyu\n",
        "    fraud_amt = df[df['isFraud']==1]['TransactionAmt'].dropna()\n",
        "    legit_amt = df[df['isFraud']==0]['TransactionAmt'].dropna()\n",
        "    statistic, p_value = mannwhitneyu(fraud_amt, legit_amt, alternative='two-sided')\n",
        "    print(f\"Mann-Whitney U test p-value: {p_value:.6f}\")\n",
        "    print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
        "    \n",
        "    # Comprehensive visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Box plot\n",
        "    df.boxplot(column='TransactionAmt', by='isFraud', ax=axes[0, 0])\n",
        "    axes[0, 0].set_title('Transaction Amount by Fraud Status', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Fraud Status (0=Legitimate, 1=Fraud)')\n",
        "    axes[0, 0].set_ylabel('Transaction Amount')\n",
        "    axes[0, 0].set_yscale('log')\n",
        "    plt.suptitle('')\n",
        "    \n",
        "    # Violin plot\n",
        "    sns.violinplot(data=df, x='isFraud', y='TransactionAmt', ax=axes[0, 1])\n",
        "    axes[0, 1].set_title('Distribution by Fraud Status', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Fraud Status (0=Legitimate, 1=Fraud)')\n",
        "    axes[0, 1].set_ylabel('Transaction Amount')\n",
        "    axes[0, 1].set_yscale('log')\n",
        "    \n",
        "    # Histogram overlay\n",
        "    axes[1, 0].hist(df[df['isFraud']==0]['TransactionAmt'], bins=50, alpha=0.6, label='Legitimate', color='blue', density=True)\n",
        "    axes[1, 0].hist(df[df['isFraud']==1]['TransactionAmt'], bins=50, alpha=0.6, label='Fraud', color='red', density=True)\n",
        "    axes[1, 0].set_title('Transaction Amount Distribution by Fraud Status', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Transaction Amount')\n",
        "    axes[1, 0].set_ylabel('Density')\n",
        "    axes[1, 0].set_xlim(0, df['TransactionAmt'].quantile(0.99))\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Scatter plot (sample for performance)\n",
        "    sample_size = min(5000, len(df))\n",
        "    sample_df = df.sample(sample_size, random_state=42)\n",
        "    axes[1, 1].scatter(sample_df['isFraud'], sample_df['TransactionAmt'], alpha=0.3, s=10)\n",
        "    axes[1, 1].set_title('Transaction Amount vs Fraud Status (Sample)', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Fraud Status (0=Legitimate, 1=Fraud)')\n",
        "    axes[1, 1].set_ylabel('Transaction Amount')\n",
        "    axes[1, 1].set_yscale('log')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/bivariate_transaction_fraud.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bivariate: Numerical feature pairs\n",
        "print(\"\\nBivariate Analysis: Numerical Feature Pairs\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select key numerical features for pairwise analysis\n",
        "pair_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5']\n",
        "pair_features = [f for f in pair_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "if len(pair_features) >= 2:\n",
        "    # Correlation matrix\n",
        "    corr_matrix = df[pair_features].corr()\n",
        "    \n",
        "    # Visualize correlation matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title('Bivariate Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/bivariate_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Scatter plot matrix (sample for performance)\n",
        "    sample_size = min(2000, len(df))\n",
        "    sample_df = df.sample(sample_size, random_state=42)\n",
        "    \n",
        "    # Create pairplot for top features\n",
        "    if len(pair_features) <= 4:\n",
        "        sns.pairplot(sample_df[pair_features + ['isFraud']], hue='isFraud', diag_kind='kde', \n",
        "                     plot_kws={'alpha': 0.5, 's': 10})\n",
        "        plt.savefig('../../outputs/figures/bivariate_pairplot.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    \n",
        "    print(\"\\nTop Correlated Pairs:\")\n",
        "    print(\"-\" * 40)\n",
        "    # Get upper triangle of correlation matrix\n",
        "    corr_pairs = []\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i+1, len(corr_matrix.columns)):\n",
        "            corr_pairs.append({\n",
        "                'Feature1': corr_matrix.columns[i],\n",
        "                'Feature2': corr_matrix.columns[j],\n",
        "                'Correlation': corr_matrix.iloc[i, j]\n",
        "            })\n",
        "    corr_pairs_df = pd.DataFrame(corr_pairs).sort_values('Correlation', key=abs, ascending=False)\n",
        "    display(corr_pairs_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bivariate: Categorical vs Numerical\n",
        "print(\"\\nBivariate Analysis: Categorical vs Numerical\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'ProductCD' in df.columns and 'TransactionAmt' in df.columns:\n",
        "    # ProductCD vs TransactionAmt\n",
        "    product_stats = df.groupby('ProductCD')['TransactionAmt'].agg(['count', 'mean', 'median', 'std'])\n",
        "    product_stats.columns = ['Count', 'Mean', 'Median', 'Std']\n",
        "    print(\"\\nTransaction Amount Statistics by ProductCD:\")\n",
        "    display(product_stats)\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Box plot\n",
        "    df.boxplot(column='TransactionAmt', by='ProductCD', ax=axes[0])\n",
        "    axes[0].set_title('Transaction Amount by ProductCD', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_xlabel('ProductCD')\n",
        "    axes[0].set_ylabel('Transaction Amount')\n",
        "    axes[0].set_yscale('log')\n",
        "    plt.suptitle('')\n",
        "    \n",
        "    # Bar plot of means\n",
        "    product_stats['Mean'].plot(kind='bar', ax=axes[1], color='steelblue')\n",
        "    axes[1].set_title('Mean Transaction Amount by ProductCD', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_xlabel('ProductCD')\n",
        "    axes[1].set_ylabel('Mean Transaction Amount')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/bivariate_product_transaction.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "if 'card4' in df.columns and 'TransactionAmt' in df.columns:\n",
        "    # Card4 vs TransactionAmt\n",
        "    card_stats = df.groupby('card4')['TransactionAmt'].agg(['count', 'mean', 'median'])\n",
        "    card_stats.columns = ['Count', 'Mean', 'Median']\n",
        "    print(\"\\nTransaction Amount Statistics by Card Type:\")\n",
        "    display(card_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bivariate: Categorical vs Categorical\n",
        "print(\"\\nBivariate Analysis: Categorical vs Categorical\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'ProductCD' in df.columns and 'card4' in df.columns:\n",
        "    # Contingency table\n",
        "    contingency_table = pd.crosstab(df['ProductCD'], df['card4'])\n",
        "    print(\"\\nContingency Table: ProductCD vs Card4\")\n",
        "    display(contingency_table)\n",
        "    \n",
        "    # Chi-square test\n",
        "    from scipy.stats import chi2_contingency\n",
        "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "    print(f\"\\nChi-square Test:\")\n",
        "    print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
        "    print(f\"  p-value: {p_value:.6f}\")\n",
        "    print(f\"  Degrees of freedom: {dof}\")\n",
        "    print(f\"  Significant association: {'Yes' if p_value < 0.05 else 'No'}\")\n",
        "    \n",
        "    # Visualization\n",
        "    contingency_pct = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    contingency_pct.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
        "    plt.title('ProductCD vs Card4 (Percentage)', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('ProductCD')\n",
        "    plt.ylabel('Percentage (%)')\n",
        "    plt.legend(title='Card Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/bivariate_product_card.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multivariate Analysis\n",
        "\n",
        "Multivariate analysis examines relationships among multiple variables simultaneously to identify complex patterns and interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multivariate: Correlation matrix\n",
        "print(\"Multivariate Analysis: Correlation Matrix\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "key_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5', \n",
        "                'addr1', 'addr2', 'dist1', 'dist2', 'isFraud']\n",
        "key_features = [f for f in key_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "if len(key_features) > 1:\n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = df[key_features].corr()\n",
        "    \n",
        "    # Visualize correlation matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, \n",
        "                xticklabels=True, yticklabels=True)\n",
        "    plt.title('Multivariate Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/multivariate_correlation.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Features most correlated with fraud\n",
        "    if 'isFraud' in corr_matrix.columns:\n",
        "        fraud_corr = corr_matrix['isFraud'].sort_values(ascending=False)\n",
        "        print(\"\\nFeatures Most Correlated with Fraud:\")\n",
        "        print(\"-\" * 40)\n",
        "        display(fraud_corr)\n",
        "        \n",
        "        # Visualize correlation with fraud\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        fraud_corr[fraud_corr.index != 'isFraud'].plot(kind='barh', color='steelblue')\n",
        "        plt.title('Correlation with Fraud (isFraud)', fontsize=12, fontweight='bold')\n",
        "        plt.xlabel('Correlation Coefficient')\n",
        "        plt.ylabel('Features')\n",
        "        plt.grid(True, alpha=0.3, axis='x')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('../../outputs/figures/multivariate_fraud_correlation.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    \n",
        "    print(\"\\nMultivariate correlation analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multivariate: Principal Component Analysis (PCA)\n",
        "print(\"\\nMultivariate Analysis: Principal Component Analysis (PCA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical features for PCA\n",
        "pca_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5', \n",
        "                'addr1', 'addr2', 'dist1', 'dist2']\n",
        "pca_features = [f for f in pca_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "if len(pca_features) >= 3:\n",
        "    # Prepare data\n",
        "    X_pca = df[pca_features].fillna(df[pca_features].median())\n",
        "    \n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_pca)\n",
        "    \n",
        "    # Perform PCA\n",
        "    pca = PCA(n_components=min(5, len(pca_features)))\n",
        "    pca_result = pca.fit_transform(X_scaled)\n",
        "    \n",
        "    # Explained variance\n",
        "    explained_variance = pca.explained_variance_ratio_\n",
        "    cumulative_variance = np.cumsum(explained_variance)\n",
        "    \n",
        "    print(f\"\\nExplained Variance by Component:\")\n",
        "    for i, (var, cum_var) in enumerate(zip(explained_variance, cumulative_variance)):\n",
        "        print(f\"  PC{i+1}: {var:.4f} ({var*100:.2f}%) - Cumulative: {cum_var:.4f} ({cum_var*100:.2f}%)\")\n",
        "    \n",
        "    # Visualize explained variance\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Scree plot\n",
        "    axes[0].bar(range(1, len(explained_variance)+1), explained_variance, color='steelblue', alpha=0.7)\n",
        "    axes[0].plot(range(1, len(explained_variance)+1), explained_variance, 'ro-', color='red')\n",
        "    axes[0].set_xlabel('Principal Component')\n",
        "    axes[0].set_ylabel('Explained Variance Ratio')\n",
        "    axes[0].set_title('Scree Plot', fontsize=12, fontweight='bold')\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Cumulative variance\n",
        "    axes[1].plot(range(1, len(cumulative_variance)+1), cumulative_variance, 'bo-', color='green')\n",
        "    axes[1].axhline(y=0.8, color='r', linestyle='--', label='80% Variance')\n",
        "    axes[1].axhline(y=0.9, color='orange', linestyle='--', label='90% Variance')\n",
        "    axes[1].set_xlabel('Principal Component')\n",
        "    axes[1].set_ylabel('Cumulative Explained Variance')\n",
        "    axes[1].set_title('Cumulative Explained Variance', fontsize=12, fontweight='bold')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/multivariate_pca.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # PCA components visualization (first 2 components)\n",
        "    if 'isFraud' in df.columns:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], \n",
        "                            c=df['isFraud'], alpha=0.5, cmap='coolwarm', s=10)\n",
        "        plt.colorbar(scatter, label='Fraud Status')\n",
        "        plt.xlabel(f'PC1 ({explained_variance[0]*100:.2f}% variance)')\n",
        "        plt.ylabel(f'PC2 ({explained_variance[1]*100:.2f}% variance)')\n",
        "        plt.title('PCA: First Two Principal Components', fontsize=12, fontweight='bold')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('../../outputs/figures/multivariate_pca_scatter.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    \n",
        "    # Feature contributions to principal components\n",
        "    components_df = pd.DataFrame(\n",
        "        pca.components_.T,\n",
        "        columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
        "        index=pca_features\n",
        "    )\n",
        "    print(\"\\nFeature Contributions to Principal Components:\")\n",
        "    display(components_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multivariate: Cluster Analysis (K-Means)\n",
        "print(\"\\nMultivariate Analysis: Cluster Analysis (K-Means)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select features for clustering\n",
        "cluster_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5']\n",
        "cluster_features = [f for f in cluster_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "if len(cluster_features) >= 2:\n",
        "    # Prepare data (sample for performance)\n",
        "    sample_size = min(5000, len(df))\n",
        "    sample_df = df.sample(sample_size, random_state=42)\n",
        "    X_cluster = sample_df[cluster_features].fillna(sample_df[cluster_features].median())\n",
        "    \n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
        "    \n",
        "    # Determine optimal number of clusters using elbow method\n",
        "    inertias = []\n",
        "    K_range = range(2, 8)\n",
        "    for k in K_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(X_cluster_scaled)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "    \n",
        "    # Visualize elbow method\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(K_range, inertias, 'bo-', color='steelblue')\n",
        "    plt.xlabel('Number of Clusters (k)')\n",
        "    plt.ylabel('Inertia')\n",
        "    plt.title('Elbow Method for Optimal k', fontsize=12, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/multivariate_elbow_method.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Perform clustering with optimal k (let's use k=3)\n",
        "    k = 3\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(X_cluster_scaled)\n",
        "    \n",
        "    # Add cluster labels to sample dataframe\n",
        "    sample_df = sample_df.copy()\n",
        "    sample_df['Cluster'] = clusters\n",
        "    \n",
        "    # Analyze clusters\n",
        "    print(f\"\\nCluster Analysis (k={k}):\")\n",
        "    cluster_summary = sample_df.groupby('Cluster')[cluster_features].mean()\n",
        "    display(cluster_summary)\n",
        "    \n",
        "    # Compare clusters with fraud status if available\n",
        "    if 'isFraud' in sample_df.columns:\n",
        "        cluster_fraud = sample_df.groupby('Cluster')['isFraud'].agg(['count', 'mean'])\n",
        "        cluster_fraud.columns = ['Count', 'Fraud_Rate']\n",
        "        print(\"\\nFraud Rate by Cluster:\")\n",
        "        display(cluster_fraud)\n",
        "        \n",
        "        # Visualize clusters\n",
        "        if len(cluster_features) >= 2:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "            \n",
        "            # Clusters\n",
        "            scatter1 = axes[0].scatter(X_cluster_scaled[:, 0], X_cluster_scaled[:, 1], \n",
        "                                     c=clusters, cmap='viridis', alpha=0.6, s=20)\n",
        "            axes[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "                           c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
        "            axes[0].set_xlabel(f'{cluster_features[0]} (standardized)')\n",
        "            axes[0].set_ylabel(f'{cluster_features[1]} (standardized)')\n",
        "            axes[0].set_title('K-Means Clustering', fontsize=12, fontweight='bold')\n",
        "            axes[0].legend()\n",
        "            axes[0].grid(True, alpha=0.3)\n",
        "            plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
        "            \n",
        "            # Fraud status\n",
        "            scatter2 = axes[1].scatter(X_cluster_scaled[:, 0], X_cluster_scaled[:, 1],\n",
        "                                     c=sample_df['isFraud'], cmap='coolwarm', alpha=0.6, s=20)\n",
        "            axes[1].set_xlabel(f'{cluster_features[0]} (standardized)')\n",
        "            axes[1].set_ylabel(f'{cluster_features[1]} (standardized)')\n",
        "            axes[1].set_title('Fraud Status', fontsize=12, fontweight='bold')\n",
        "            axes[1].grid(True, alpha=0.3)\n",
        "            plt.colorbar(scatter2, ax=axes[1], label='Fraud Status')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.savefig('../../outputs/figures/multivariate_clustering.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary and Conclusions\n",
        "print(\"=\"*80)\n",
        "print(\"UNIVARIATE, BIVARIATE, AND MULTIVARIATE ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. Univariate Analysis:\")\n",
        "print(\"   - Analyzed individual variable distributions, central tendencies, and variability\")\n",
        "print(\"   - Identified key statistical measures (mean, median, std, skewness, kurtosis)\")\n",
        "print(\"   - Examined normality of distributions\")\n",
        "print(\"   - Analyzed both numerical and categorical features\")\n",
        "\n",
        "print(\"\\n2. Bivariate Analysis:\")\n",
        "print(\"   - Examined relationships between pairs of variables\")\n",
        "print(\"   - Identified correlations between numerical features\")\n",
        "print(\"   - Analyzed associations between categorical and numerical features\")\n",
        "print(\"   - Performed statistical tests to validate relationships\")\n",
        "\n",
        "print(\"\\n3. Multivariate Analysis:\")\n",
        "print(\"   - Explored complex relationships among multiple variables\")\n",
        "print(\"   - Performed Principal Component Analysis (PCA) to identify key dimensions\")\n",
        "print(\"   - Conducted cluster analysis to identify patterns in data\")\n",
        "print(\"   - Identified features most correlated with fraud\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Analysis Complete! Check outputs/figures/ for visualizations.\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
