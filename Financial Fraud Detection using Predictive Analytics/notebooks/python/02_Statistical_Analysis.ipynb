{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Analysis - Fraud Detection Dataset\n",
        "\n",
        "This notebook performs comprehensive statistical analysis including:\n",
        "1. **Descriptive Statistics** - Mean, median, mode, standard deviation, variance, skewness, kurtosis\n",
        "2. **Inferential Statistics** - Hypothesis testing, confidence intervals, t-tests, chi-square tests\n",
        "3. **Exploratory Statistics** - Correlation analysis, feature relationships, statistical tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import normaltest, shapiro, chi2_contingency, ttest_ind, mannwhitneyu\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path = Path('../../data/fraud_data.csv')\n",
        "df = pd.read_csv(data_path)\n",
        "print(f\"Data loaded: {df.shape}\")\n",
        "print(f\"Target variable distribution:\\n{df['isFraud'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Descriptive Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics for numerical features\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "key_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']\n",
        "key_features = [f for f in key_features if f in numerical_cols]\n",
        "\n",
        "print(\"Descriptive Statistics for Key Numerical Features:\")\n",
        "print(\"=\"*80)\n",
        "desc_stats = df[key_features].describe()\n",
        "display(desc_stats)\n",
        "\n",
        "# Additional statistics: skewness and kurtosis\n",
        "print(\"\\nSkewness and Kurtosis:\")\n",
        "print(\"=\"*80)\n",
        "skew_kurt = pd.DataFrame({\n",
        "    'Skewness': df[key_features].skew(),\n",
        "    'Kurtosis': df[key_features].kurtosis()\n",
        "})\n",
        "display(skew_kurt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics by fraud status\n",
        "if 'TransactionAmt' in df.columns:\n",
        "    print(\"Transaction Amount Statistics by Fraud Status:\")\n",
        "    print(\"=\"*80)\n",
        "    fraud_stats = df.groupby('isFraud')['TransactionAmt'].agg([\n",
        "        'count', 'mean', 'median', 'std', 'min', 'max', \n",
        "        'skew', pd.Series.kurt\n",
        "    ]).round(4)\n",
        "    fraud_stats.columns = ['Count', 'Mean', 'Median', 'Std', 'Min', 'Max', 'Skewness', 'Kurtosis']\n",
        "    display(fraud_stats)\n",
        "    \n",
        "    # Visualize distributions\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Histogram\n",
        "    df[df['isFraud']==0]['TransactionAmt'].hist(bins=50, alpha=0.7, label='Legitimate', ax=axes[0], color='blue')\n",
        "    df[df['isFraud']==1]['TransactionAmt'].hist(bins=50, alpha=0.7, label='Fraud', ax=axes[0], color='red')\n",
        "    axes[0].set_xlabel('Transaction Amount')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Transaction Amount Distribution by Fraud Status')\n",
        "    axes[0].legend()\n",
        "    axes[0].set_xlim(0, df['TransactionAmt'].quantile(0.99))\n",
        "    \n",
        "    # Box plot\n",
        "    df.boxplot(column='TransactionAmt', by='isFraud', ax=axes[1])\n",
        "    axes[1].set_xlabel('Fraud Status')\n",
        "    axes[1].set_ylabel('Transaction Amount')\n",
        "    axes[1].set_title('Transaction Amount by Fraud Status')\n",
        "    axes[1].set_yscale('log')\n",
        "    plt.suptitle('')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/descriptive_stats_transaction.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferential Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hypothesis Test 1: Test if mean transaction amount differs between fraud and legitimate transactions\n",
        "if 'TransactionAmt' in df.columns:\n",
        "    print(\"Hypothesis Test: Transaction Amount\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"H0: Mean transaction amount is the same for fraud and legitimate transactions\")\n",
        "    print(\"H1: Mean transaction amount differs between fraud and legitimate transactions\")\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    fraud_amt = df[df['isFraud']==1]['TransactionAmt'].dropna()\n",
        "    legit_amt = df[df['isFraud']==0]['TransactionAmt'].dropna()\n",
        "    \n",
        "    # Check normality (Shapiro-Wilk test on sample)\n",
        "    sample_size = min(5000, len(fraud_amt), len(legit_amt))\n",
        "    _, p_fraud_norm = shapiro(fraud_amt.sample(sample_size))\n",
        "    _, p_legit_norm = shapiro(legit_amt.sample(sample_size))\n",
        "    \n",
        "    print(f\"Normality test p-values:\")\n",
        "    print(f\"  Fraud transactions: {p_fraud_norm:.6f}\")\n",
        "    print(f\"  Legitimate transactions: {p_legit_norm:.6f}\")\n",
        "    print(f\"  (Both distributions are likely non-normal, p < 0.05)\")\n",
        "    \n",
        "    # Use Mann-Whitney U test (non-parametric)\n",
        "    statistic, p_value = mannwhitneyu(fraud_amt, legit_amt, alternative='two-sided')\n",
        "    print(f\"\\nMann-Whitney U Test Results:\")\n",
        "    print(f\"  Statistic: {statistic:.4f}\")\n",
        "    print(f\"  p-value: {p_value:.6f}\")\n",
        "    print(f\"  Significance level: 0.05\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(f\"  Result: REJECT H0 - Mean transaction amounts are significantly different\")\n",
        "    else:\n",
        "        print(f\"  Result: FAIL TO REJECT H0 - No significant difference in mean transaction amounts\")\n",
        "    \n",
        "    # Also perform t-test for comparison\n",
        "    t_stat, t_pvalue = ttest_ind(fraud_amt, legit_amt)\n",
        "    print(f\"\\nIndependent t-test Results (for comparison):\")\n",
        "    print(f\"  t-statistic: {t_stat:.4f}\")\n",
        "    print(f\"  p-value: {t_pvalue:.6f}\")\n",
        "    \n",
        "    # Calculate confidence intervals\n",
        "    fraud_mean = fraud_amt.mean()\n",
        "    fraud_std = fraud_amt.std()\n",
        "    fraud_se = fraud_std / np.sqrt(len(fraud_amt))\n",
        "    fraud_ci = stats.norm.interval(0.95, loc=fraud_mean, scale=fraud_se)\n",
        "    \n",
        "    legit_mean = legit_amt.mean()\n",
        "    legit_std = legit_amt.std()\n",
        "    legit_se = legit_std / np.sqrt(len(legit_amt))\n",
        "    legit_ci = stats.norm.interval(0.95, loc=legit_mean, scale=legit_se)\n",
        "    \n",
        "    print(f\"\\n95% Confidence Intervals:\")\n",
        "    print(f\"  Fraud transactions: ${fraud_ci[0]:.2f} - ${fraud_ci[1]:.2f} (mean: ${fraud_mean:.2f})\")\n",
        "    print(f\"  Legitimate transactions: ${legit_ci[0]:.2f} - ${legit_ci[1]:.2f} (mean: ${legit_mean:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hypothesis Test 2: Chi-square test for categorical variables\n",
        "print(\"Chi-square Test: ProductCD and Fraud\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'ProductCD' in df.columns:\n",
        "    # Create contingency table\n",
        "    contingency_table = pd.crosstab(df['ProductCD'], df['isFraud'])\n",
        "    print(\"Contingency Table:\")\n",
        "    display(contingency_table)\n",
        "    \n",
        "    # Chi-square test\n",
        "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "    \n",
        "    print(f\"\\nChi-square Test Results:\")\n",
        "    print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
        "    print(f\"  p-value: {p_value:.6f}\")\n",
        "    print(f\"  Degrees of freedom: {dof}\")\n",
        "    print(f\"  Significance level: 0.05\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(f\"  Result: REJECT H0 - ProductCD is significantly associated with fraud\")\n",
        "    else:\n",
        "        print(f\"  Result: FAIL TO REJECT H0 - No significant association\")\n",
        "    \n",
        "    # Visualize\n",
        "    contingency_pct = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100\n",
        "    contingency_pct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "    plt.title('Fraud Rate by ProductCD', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('ProductCD')\n",
        "    plt.ylabel('Percentage (%)')\n",
        "    plt.legend(['Legitimate', 'Fraud'])\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../../outputs/figures/chi_square_productcd.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hypothesis Test 3: Test for card type and fraud\n",
        "if 'card4' in df.columns:\n",
        "    print(\"Chi-square Test: Card Type (card4) and Fraud\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    contingency_table = pd.crosstab(df['card4'], df['isFraud'])\n",
        "    print(\"Contingency Table:\")\n",
        "    display(contingency_table)\n",
        "    \n",
        "    # Chi-square test\n",
        "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "    \n",
        "    print(f\"\\nChi-square Test Results:\")\n",
        "    print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
        "    print(f\"  p-value: {p_value:.6f}\")\n",
        "    print(f\"  Degrees of freedom: {dof}\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(f\"  Result: REJECT H0 - Card type is significantly associated with fraud\")\n",
        "    else:\n",
        "        print(f\"  Result: FAIL TO REJECT H0 - No significant association\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "print(\"Correlation Analysis\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select key numerical features\n",
        "key_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5', \n",
        "                'addr1', 'addr2', 'dist1', 'dist2', 'isFraud']\n",
        "key_features = [f for f in key_features if f in df.columns and df[f].dtype in [np.int64, np.float64]]\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = df[key_features].corr()\n",
        "\n",
        "# Visualize correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Key Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../outputs/figures/correlation_matrix_statistical.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Features most correlated with fraud\n",
        "if 'isFraud' in corr_matrix.columns:\n",
        "    fraud_corr = corr_matrix['isFraud'].sort_values(ascending=False)\n",
        "    print(\"\\nFeatures most correlated with Fraud:\")\n",
        "    print(\"=\"*80)\n",
        "    display(fraud_corr)\n",
        "    \n",
        "    # Statistical significance of correlations\n",
        "    print(\"\\nStatistical Significance of Correlations with Fraud:\")\n",
        "    print(\"=\"*80)\n",
        "    n = len(df)\n",
        "    significant_features = []\n",
        "    for feature in fraud_corr.index:\n",
        "        if feature != 'isFraud':\n",
        "            corr_coef = fraud_corr[feature]\n",
        "            # Test significance of correlation\n",
        "            t_stat = corr_coef * np.sqrt((n - 2) / (1 - corr_coef**2))\n",
        "            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 2))\n",
        "            if p_value < 0.05:\n",
        "                significant_features.append((feature, corr_coef, p_value))\n",
        "    \n",
        "    if significant_features:\n",
        "        sig_df = pd.DataFrame(significant_features, columns=['Feature', 'Correlation', 'p-value'])\n",
        "        print(\"Significantly correlated features (p < 0.05):\")\n",
        "        display(sig_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary by fraud status for multiple features\n",
        "print(\"Statistical Summary by Fraud Status\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select a subset of numerical features for analysis\n",
        "analysis_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5']\n",
        "analysis_features = [f for f in analysis_features if f in df.columns]\n",
        "\n",
        "if analysis_features:\n",
        "    summary_stats = df.groupby('isFraud')[analysis_features].agg(['mean', 'median', 'std', 'skew'])\n",
        "    print(\"\\nSummary Statistics by Fraud Status:\")\n",
        "    display(summary_stats)\n",
        "    \n",
        "    # Perform statistical tests for each feature\n",
        "    print(\"\\nStatistical Tests for Each Feature:\")\n",
        "    print(\"=\"*80)\n",
        "    test_results = []\n",
        "    \n",
        "    for feature in analysis_features:\n",
        "        fraud_data = df[df['isFraud']==1][feature].dropna()\n",
        "        legit_data = df[df['isFraud']==0][feature].dropna()\n",
        "        \n",
        "        if len(fraud_data) > 0 and len(legit_data) > 0:\n",
        "            # Mann-Whitney U test\n",
        "            statistic, p_value = mannwhitneyu(fraud_data, legit_data, alternative='two-sided')\n",
        "            test_results.append({\n",
        "                'Feature': feature,\n",
        "                'Test': 'Mann-Whitney U',\n",
        "                'Statistic': statistic,\n",
        "                'p-value': p_value,\n",
        "                'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
        "            })\n",
        "    \n",
        "    test_df = pd.DataFrame(test_results)\n",
        "    display(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary and Conclusions\n",
        "print(\"=\"*80)\n",
        "print(\"STATISTICAL ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. Descriptive Statistics:\")\n",
        "print(\"   - Calculated mean, median, std, skewness, and kurtosis for key features\")\n",
        "print(\"   - Compared statistics between fraud and legitimate transactions\")\n",
        "\n",
        "print(\"\\n2. Inferential Statistics:\")\n",
        "print(\"   - Performed hypothesis tests to compare fraud and legitimate transactions\")\n",
        "print(\"   - Used non-parametric tests (Mann-Whitney U) due to non-normal distributions\")\n",
        "print(\"   - Calculated confidence intervals for key metrics\")\n",
        "print(\"   - Performed chi-square tests for categorical variables\")\n",
        "\n",
        "print(\"\\n3. Exploratory Statistics:\")\n",
        "print(\"   - Analyzed correlations between features and fraud\")\n",
        "print(\"   - Identified statistically significant relationships\")\n",
        "print(\"   - Explored feature distributions by fraud status\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Statistical Analysis Complete!\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
