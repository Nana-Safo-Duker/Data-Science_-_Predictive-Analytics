{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Analysis\n",
        "\n",
        "This notebook performs machine learning analysis for customer segmentation:\n",
        "\n",
        "1. **Data Preparation**: Feature engineering and preprocessing\n",
        "2. **Clustering Analysis**: K-Means and Hierarchical clustering\n",
        "3. **Cluster Evaluation**: Silhouette score, Davies-Bouldin index\n",
        "4. **Cluster Interpretation**: Analysis of cluster characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "# Set paths\n",
        "data_path = Path('../../data/Customers.csv')\n",
        "results_path = Path('../../results')\n",
        "results_path.mkdir(exist_ok=True)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print('Data loaded successfully!')\n",
        "print(f'Shape: {df.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML analysis\n",
        "print(\"=\" * 50)\n",
        "print(\"DATA PREPARATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Encode categorical variables\n",
        "le_country = LabelEncoder()\n",
        "le_city = LabelEncoder()\n",
        "\n",
        "df_encoded = df.copy()\n",
        "df_encoded['Country_encoded'] = le_country.fit_transform(df['Country'])\n",
        "df_encoded['City_encoded'] = le_city.fit_transform(df['City'])\n",
        "\n",
        "# Select features\n",
        "features = ['CustomerID', 'Country_encoded', 'City_encoded']\n",
        "X = df_encoded[features].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"Data shape: {X_scaled.shape}\")\n",
        "print(f\"Features: {features}\")\n",
        "print(f\"Number of samples: {X_scaled.shape[0]}\")\n",
        "print(f\"Number of features: {X_scaled.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Determine Optimal Number of Clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine optimal number of clusters using Elbow method and Silhouette score\n",
        "print(\"=\" * 50)\n",
        "print(\"DETERMINING OPTIMAL NUMBER OF CLUSTERS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "max_clusters = min(8, len(X_scaled) // 2)\n",
        "K_range = range(2, max_clusters + 1)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "\n",
        "# Plot Elbow method and Silhouette scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (k)')\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].set_title('Elbow Method for Optimal k')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(K_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (k)')\n",
        "axes[1].set_ylabel('Silhouette Score')\n",
        "axes[1].set_title('Silhouette Score for Optimal k')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_path / 'optimal_clusters.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Find optimal k (highest silhouette score)\n",
        "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
        "print(f\"\\nOptimal number of clusters: {optimal_k}\")\n",
        "print(f\"Silhouette score: {max(silhouette_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. K-Means Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform K-Means clustering\n",
        "print(\"=\" * 50)\n",
        "print(\"K-MEANS CLUSTERING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "df_clustered = df_encoded.copy()\n",
        "df_clustered['Cluster'] = clusters\n",
        "\n",
        "# Evaluate clustering\n",
        "silhouette = silhouette_score(X_scaled, clusters)\n",
        "davies_bouldin = davies_bouldin_score(X_scaled, clusters)\n",
        "calinski_harabasz = calinski_harabasz_score(X_scaled, clusters)\n",
        "\n",
        "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
        "print(f\"Davies-Bouldin Score: {davies_bouldin:.4f}\")\n",
        "print(f\"Calinski-Harabasz Score: {calinski_harabasz:.4f}\")\n",
        "\n",
        "# Cluster statistics\n",
        "print(\"\\n=== Cluster Statistics ===\")\n",
        "cluster_stats = df_clustered.groupby('Cluster').agg({\n",
        "    'CustomerID': 'count',\n",
        "    'Country_encoded': 'mean',\n",
        "    'City_encoded': 'mean'\n",
        "}).round(2)\n",
        "cluster_stats.columns = ['Customer_Count', 'Avg_Country_encoded', 'Avg_City_encoded']\n",
        "print(cluster_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize clusters using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=100)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
        "            c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
        "plt.title(f'K-Means Clustering (k={optimal_k})')\n",
        "plt.colorbar(scatter, label='Cluster')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_path / 'kmeans_clustering.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hierarchical Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform Hierarchical Clustering\n",
        "print(\"=\" * 50)\n",
        "print(\"HIERARCHICAL CLUSTERING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
        "clusters_hier = hierarchical.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering\n",
        "silhouette_hier = silhouette_score(X_scaled, clusters_hier)\n",
        "davies_bouldin_hier = davies_bouldin_score(X_scaled, clusters_hier)\n",
        "calinski_harabasz_hier = calinski_harabasz_score(X_scaled, clusters_hier)\n",
        "\n",
        "print(f\"Silhouette Score: {silhouette_hier:.4f}\")\n",
        "print(f\"Davies-Bouldin Score: {davies_bouldin_hier:.4f}\")\n",
        "print(f\"Calinski-Harabasz Score: {calinski_harabasz_hier:.4f}\")\n",
        "\n",
        "# Visualize clusters using PCA\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_hier, cmap='plasma', alpha=0.6, s=100)\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
        "plt.title(f'Hierarchical Clustering (k={optimal_k})')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_path / 'hierarchical_clustering.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cluster Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze cluster characteristics\n",
        "print(\"=\" * 50)\n",
        "print(\"CLUSTER ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Country distribution by cluster\n",
        "print(\"\\n=== Top Countries by Cluster ===\")\n",
        "for cluster_id in sorted(df_clustered['Cluster'].unique()):\n",
        "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
        "    top_countries = cluster_data['Country'].value_counts().head(5)\n",
        "    print(f\"\\nCluster {cluster_id} ({len(cluster_data)} customers):\")\n",
        "    for country, count in top_countries.items():\n",
        "        print(f\"  {country}: {count} customers ({(count/len(cluster_data)*100):.1f}%)\")\n",
        "\n",
        "# City distribution by cluster\n",
        "print(\"\\n=== Top Cities by Cluster ===\")\n",
        "for cluster_id in sorted(df_clustered['Cluster'].unique()):\n",
        "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
        "    top_cities = cluster_data['City'].value_counts().head(5)\n",
        "    print(f\"\\nCluster {cluster_id}:\")\n",
        "    for city, count in top_cities.items():\n",
        "        print(f\"  {city}: {count} customers ({(count/len(cluster_data)*100):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cluster composition\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Country distribution\n",
        "country_cluster = pd.crosstab(df_clustered['Cluster'], df_clustered['Country'])\n",
        "country_cluster.plot(kind='bar', ax=axes[0], stacked=True, colormap='tab20')\n",
        "axes[0].set_xlabel('Cluster')\n",
        "axes[0].set_ylabel('Number of Customers')\n",
        "axes[0].set_title('Country Distribution by Cluster')\n",
        "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Cluster sizes\n",
        "cluster_sizes = df_clustered['Cluster'].value_counts().sort_index()\n",
        "cluster_sizes.plot(kind='bar', ax=axes[1], color='steelblue', edgecolor='black')\n",
        "axes[1].set_xlabel('Cluster')\n",
        "axes[1].set_ylabel('Number of Customers')\n",
        "axes[1].set_title('Cluster Sizes')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_path / 'cluster_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Results and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save clustered data\n",
        "df_clustered.to_csv(results_path / 'clustered_customers.csv', index=False)\n",
        "print(f\"\\n✓ Clustered data saved to {results_path / 'clustered_customers.csv'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ML ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n1. Optimal number of clusters: {optimal_k}\")\n",
        "print(\"2. Performed K-Means clustering\")\n",
        "print(\"3. Performed Hierarchical clustering\")\n",
        "print(\"4. Analyzed cluster characteristics\")\n",
        "print(\"5. Generated visualizations and saved results\")\n",
        "print(f\"\\nK-Means Performance:\")\n",
        "print(f\"  • Silhouette Score: {silhouette:.4f}\")\n",
        "print(f\"  • Davies-Bouldin Score: {davies_bouldin:.4f}\")\n",
        "print(f\"  • Calinski-Harabasz Score: {calinski_harabasz:.4f}\")\n",
        "print(f\"\\nHierarchical Clustering Performance:\")\n",
        "print(f\"  • Silhouette Score: {silhouette_hier:.4f}\")\n",
        "print(f\"  • Davies-Bouldin Score: {davies_bouldin_hier:.4f}\")\n",
        "print(f\"  • Calinski-Harabasz Score: {calinski_harabasz_hier:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
