{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Analysis\n",
        "\n",
        "This notebook performs comprehensive statistical analysis including:\n",
        "1. **Descriptive Statistics**: Mean, median, mode, standard deviation, variance, quartiles\n",
        "2. **Inferential Statistics**: Hypothesis testing, confidence intervals\n",
        "3. **Exploratory Statistics**: Distribution analysis, outlier detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, normaltest\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Set paths\n",
        "data_path = Path('../../data/Customers.csv')\n",
        "results_path = Path('../../results')\n",
        "results_path.mkdir(exist_ok=True)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print('Data loaded successfully!')\n",
        "print(f'Shape: {df.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Descriptive Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics for numerical variables\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print('=' * 50)\n",
        "print('DESCRIPTIVE STATISTICS')\n",
        "print('=' * 50)\n",
        "\n",
        "if len(numerical_cols) > 0:\n",
        "    print('\\n=== Descriptive Statistics for Numerical Variables ===')\n",
        "    df[numerical_cols].describe()\n",
        "    \n",
        "    # Additional descriptive statistics\n",
        "    print('\\n=== Additional Descriptive Statistics ===')\n",
        "    desc_stats = pd.DataFrame({\n",
        "        'Mean': df[numerical_cols].mean(),\n",
        "        'Median': df[numerical_cols].median(),\n",
        "        'Std Dev': df[numerical_cols].std(),\n",
        "        'Variance': df[numerical_cols].var(),\n",
        "        'Min': df[numerical_cols].min(),\n",
        "        'Max': df[numerical_cols].max(),\n",
        "        'Range': df[numerical_cols].max() - df[numerical_cols].min(),\n",
        "        'Q1': df[numerical_cols].quantile(0.25),\n",
        "        'Q3': df[numerical_cols].quantile(0.75),\n",
        "        'IQR': df[numerical_cols].quantile(0.75) - df[numerical_cols].quantile(0.25),\n",
        "        'Skewness': df[numerical_cols].skew(),\n",
        "        'Kurtosis': df[numerical_cols].kurtosis()\n",
        "    })\n",
        "    desc_stats.T\n",
        "else:\n",
        "    print('No numerical columns found.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics for categorical variables\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print('\\n=== Descriptive Statistics for Categorical Variables ===')\n",
        "for col in categorical_cols:\n",
        "    print(f'\\n{col}:')\n",
        "    print(f'  Count: {df[col].count()}')\n",
        "    print(f'  Unique values: {df[col].nunique()}')\n",
        "    if len(df[col].mode()) > 0:\n",
        "        print(f'  Mode: {df[col].mode()[0]}')\n",
        "        print(f'  Mode frequency: {df[col].value_counts().iloc[0]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Inferential Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confidence intervals (95%)\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print('=' * 50)\n",
        "print('INFERENTIAL STATISTICS')\n",
        "print('=' * 50)\n",
        "\n",
        "if len(numerical_cols) > 0:\n",
        "    print('\\n=== Confidence Intervals (95%) ===')\n",
        "    for col in numerical_cols:\n",
        "        mean = df[col].mean()\n",
        "        std = df[col].std()\n",
        "        n = len(df[col])\n",
        "        \n",
        "        margin_error = 1.96 * (std / np.sqrt(n))\n",
        "        ci_lower = mean - margin_error\n",
        "        ci_upper = mean + margin_error\n",
        "        \n",
        "        print(f'\\n{col}:')\n",
        "        print(f'  Mean: {mean:.2f}')\n",
        "        print(f'  95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normality tests\n",
        "print('\\n=== Normality Tests ===')\n",
        "alpha = 0.05\n",
        "for col in numerical_cols:\n",
        "    data = df[col].dropna()\n",
        "    if len(data) > 8:  # Normaltest requires at least 8 samples\n",
        "        stat, p_value = normaltest(data)\n",
        "        \n",
        "        print(f'\\n{col}:')\n",
        "        print(f'  D\\'Agostino-Pearson test:')\n",
        "        print(f'    Statistic: {stat:.4f}')\n",
        "        print(f'    p-value: {p_value:.4f}')\n",
        "        \n",
        "        if p_value > alpha:\n",
        "            print(f'    Result: Data appears to be normally distributed (p > {alpha})')\n",
        "        else:\n",
        "            print(f'    Result: Data does not appear to be normally distributed (p <= {alpha})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chi-square test for independence\n",
        "print('\\n=== Chi-Square Test for Independence ===')\n",
        "contingency_table = pd.crosstab(df['Country'], df['City'])\n",
        "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f'\\nChi-square statistic: {chi2:.4f}')\n",
        "print(f'Degrees of freedom: {dof}')\n",
        "print(f'p-value: {p_value:.4f}')\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f'\\nResult: Reject null hypothesis. Country and City are not independent (p < {alpha})')\n",
        "else:\n",
        "    print(f'\\nResult: Fail to reject null hypothesis. Country and City may be independent (p >= {alpha})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exploratory Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution analysis\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print('=' * 50)\n",
        "print('EXPLORATORY STATISTICAL ANALYSIS')\n",
        "print('=' * 50)\n",
        "\n",
        "if len(numerical_cols) > 0:\n",
        "    print('\\n=== Distribution Analysis ===')\n",
        "    for col in numerical_cols:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Histogram\n",
        "        axes[0].hist(df[col], bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "        axes[0].set_xlabel(col)\n",
        "        axes[0].set_ylabel('Frequency')\n",
        "        axes[0].set_title(f'Distribution of {col}')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Box plot\n",
        "        axes[1].boxplot(df[col], vert=True)\n",
        "        axes[1].set_ylabel(col)\n",
        "        axes[1].set_title(f'Box Plot of {col}')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(results_path / f'{col}_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outlier detection using IQR method\n",
        "print('\\n=== Outlier Detection (IQR Method) ===')\n",
        "for col in numerical_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
        "    \n",
        "    print(f'\\n{col}:')\n",
        "    print(f'  Lower bound: {lower_bound:.2f}')\n",
        "    print(f'  Upper bound: {upper_bound:.2f}')\n",
        "    print(f'  Number of outliers: {len(outliers)}')\n",
        "    if len(outliers) > 0:\n",
        "        print(f'  Outlier values: {outliers.tolist()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Central tendency and dispersion measures\n",
        "print('\\n=== Central Tendency and Dispersion Measures ===')\n",
        "measures = pd.DataFrame({\n",
        "    'Mean': df[numerical_cols].mean(),\n",
        "    'Median': df[numerical_cols].median(),\n",
        "    'Std Dev': df[numerical_cols].std(),\n",
        "    'Variance': df[numerical_cols].var(),\n",
        "    'CV (%)': (df[numerical_cols].std() / df[numerical_cols].mean() * 100)\n",
        "})\n",
        "print(measures)\n",
        "\n",
        "print('\\n✓ Statistical analysis visualizations saved to results/ directory')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('=' * 50)\n",
        "print('STATISTICAL ANALYSIS SUMMARY')\n",
        "print('=' * 50)\n",
        "print('\\n1. Descriptive Statistics:')\n",
        "print('   • Calculated measures of central tendency (mean, median, mode)')\n",
        "print('   • Calculated measures of dispersion (std dev, variance, IQR)')\n",
        "print('   • Analyzed distribution characteristics (skewness, kurtosis)')\n",
        "print('\\n2. Inferential Statistics:')\n",
        "print('   • Calculated 95% confidence intervals')\n",
        "print('   • Performed normality tests')\n",
        "print('   • Conducted chi-square tests for independence')\n",
        "print('\\n3. Exploratory Statistics:')\n",
        "print('   • Analyzed distributions')\n",
        "print('   • Detected outliers')\n",
        "print('   • Examined central tendency and dispersion')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
