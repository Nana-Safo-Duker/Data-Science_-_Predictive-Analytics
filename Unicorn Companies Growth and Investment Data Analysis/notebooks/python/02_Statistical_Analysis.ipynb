{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Descriptive, Inferential, and Exploratory Statistical Analysis\n",
        "\n",
        "This notebook performs comprehensive statistical analysis on the Unicorn Companies dataset.\n",
        "\n",
        "## Objectives\n",
        "1. Descriptive Statistics\n",
        "2. Inferential Statistics\n",
        "3. Hypothesis Testing\n",
        "4. Correlation Analysis\n",
        "5. Statistical Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind, chi2_contingency, f_oneway, pearsonr, spearmanr\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Load cleaned data\n",
        "df = pd.read_csv('../../data/Unicorn_Companies_cleaned.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Descriptive Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics for numerical variables\n",
        "numeric_cols = ['Valuation_B', 'Total_Raised_B', 'Investors Count', 'Deal Terms', \n",
        "                'Portfolio Exits', 'Years_to_Unicorn']\n",
        "\n",
        "print(\"Descriptive Statistics:\")\n",
        "desc_stats = df[numeric_cols].describe()\n",
        "print(desc_stats)\n",
        "\n",
        "# Additional statistics\n",
        "print(\"\\nAdditional Statistics:\")\n",
        "for col in numeric_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Skewness: {df[col].skew():.4f}\")\n",
        "    print(f\"  Kurtosis: {df[col].kurtosis():.4f}\")\n",
        "    print(f\"  Coefficient of Variation: {(df[col].std() / df[col].mean()):.4f}\")\n",
        "    print(f\"  Median: {df[col].median():.4f}\")\n",
        "    print(f\"  IQR: {df[col].quantile(0.75) - df[col].quantile(0.25):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferential Statistics - Hypothesis Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Compare valuations between US and China\n",
        "us_val = df[df['Country'] == 'United States']['Valuation_B'].dropna()\n",
        "china_val = df[df['Country'] == 'China']['Valuation_B'].dropna()\n",
        "\n",
        "print(\"Hypothesis Test 1: US vs China Valuations\")\n",
        "print(f\"US Mean: {us_val.mean():.2f}B, China Mean: {china_val.mean():.2f}B\")\n",
        "\n",
        "# Two-sample t-test\n",
        "t_stat, p_value = ttest_ind(us_val, china_val)\n",
        "print(f\"\\nTwo-sample t-test:\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "print(f\"Significant at α=0.05: {p_value < 0.05}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: ANOVA - Compare valuations across top industries\n",
        "top_industries = df['Industry'].value_counts().head(5).index\n",
        "industry_groups = [df[df['Industry'] == ind]['Valuation_B'].dropna() for ind in top_industries]\n",
        "\n",
        "print(\"Hypothesis Test 2: ANOVA - Valuations across Industries\")\n",
        "f_stat, p_value_anova = f_oneway(*industry_groups)\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"p-value: {p_value_anova:.4f}\")\n",
        "print(f\"Significant at α=0.05: {p_value_anova < 0.05}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 3: Chi-square test - Country vs Financial Stage\n",
        "contingency_table = pd.crosstab(df['Country'], df['Financial Stage'])\n",
        "chi2, p_value_chi2, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Hypothesis Test 3: Chi-square test - Country vs Financial Stage\")\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"p-value: {p_value_chi2:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"Significant at α=0.05: {p_value_chi2 < 0.05}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "corr_cols = ['Valuation_B', 'Total_Raised_B', 'Investors Count', 'Deal Terms', \n",
        "             'Portfolio Exits', 'Years_to_Unicorn']\n",
        "corr_matrix = df[corr_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Numerical Variables')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/plots/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Pearson correlation tests\n",
        "print(\"Pearson Correlation Tests:\")\n",
        "print(f\"Valuation vs Total Raised: r={pearsonr(df['Valuation_B'].dropna(), df['Total_Raised_B'].dropna())[0]:.4f}, p={pearsonr(df['Valuation_B'].dropna(), df['Total_Raised_B'].dropna())[1]:.4f}\")\n",
        "print(f\"Valuation vs Investors Count: r={pearsonr(df['Valuation_B'].dropna(), df['Investors Count'].dropna())[0]:.4f}, p={pearsonr(df['Valuation_B'].dropna(), df['Investors Count'].dropna())[1]:.4f}\")\n",
        "print(f\"Total Raised vs Years to Unicorn: r={pearsonr(df['Total_Raised_B'].dropna(), df['Years_to_Unicorn'].dropna())[0]:.4f}, p={pearsonr(df['Total_Raised_B'].dropna(), df['Years_to_Unicorn'].dropna())[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Confidence Intervals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate 95% confidence intervals for mean valuation\n",
        "mean_val = df['Valuation_B'].mean()\n",
        "std_val = df['Valuation_B'].std()\n",
        "n = len(df['Valuation_B'].dropna())\n",
        "se = std_val / np.sqrt(n)\n",
        "confidence_level = 0.95\n",
        "alpha = 1 - confidence_level\n",
        "t_critical = stats.t.ppf(1 - alpha/2, n-1)\n",
        "\n",
        "ci_lower = mean_val - t_critical * se\n",
        "ci_upper = mean_val + t_critical * se\n",
        "\n",
        "print(f\"95% Confidence Interval for Mean Valuation:\")\n",
        "print(f\"Mean: {mean_val:.2f}B\")\n",
        "print(f\"Confidence Interval: [{ci_lower:.2f}B, {ci_upper:.2f}B]\")\n",
        "print(f\"Margin of Error: {t_critical * se:.2f}B\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
