{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Analysis: Unicorn Companies\n",
        "\n",
        "This notebook performs comprehensive machine learning analysis on the Unicorn Companies dataset.\n",
        "\n",
        "## Objectives\n",
        "1. Data preprocessing for ML\n",
        "2. Feature engineering\n",
        "3. Regression models to predict Valuation\n",
        "4. Classification models to predict Financial Stage\n",
        "5. Model evaluation and comparison\n",
        "6. Feature importance analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Create results directory\n",
        "os.makedirs('../../results/models', exist_ok=True)\n",
        "os.makedirs('../../results/plots', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data\n",
        "df = pd.read_csv('../../data/Unicorn_Companies_cleaned.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "df_ml = df.copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_cols = ['Country', 'Industry', 'Financial Stage']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_ml[f'{col}_encoded'] = le.fit_transform(df_ml[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Select features for modeling\n",
        "feature_cols = ['Total_Raised_B', 'Investors Count', 'Deal Terms', \n",
        "                'Portfolio Exits', 'Years_to_Unicorn', 'Founded_Year',\n",
        "                'Country_encoded', 'Industry_encoded']\n",
        "\n",
        "# Remove rows with missing target values\n",
        "df_ml = df_ml.dropna(subset=['Valuation_B'])\n",
        "\n",
        "# Fill remaining missing values\n",
        "df_ml[feature_cols] = df_ml[feature_cols].fillna(df_ml[feature_cols].median())\n",
        "\n",
        "print(f\"Final dataset shape: {df_ml.shape}\")\n",
        "print(f\"Features: {feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Regression: Predict Valuation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for regression\n",
        "X_reg = df_ml[feature_cols]\n",
        "y_reg = df_ml['Valuation_B']\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_reg = StandardScaler()\n",
        "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
        "\n",
        "print(f\"Training set size: {X_train_reg.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_reg.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "y_pred_rf = rf_reg.predict(X_test_reg)\n",
        "mse_rf = mean_squared_error(y_test_reg, y_pred_rf)\n",
        "r2_rf = r2_score(y_test_reg, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Regressor:\")\n",
        "print(f\"  MSE: {mse_rf:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mse_rf):.4f}\")\n",
        "print(f\"  R² Score: {r2_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost Regressor\n",
        "xgb_reg = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "xgb_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "y_pred_xgb = xgb_reg.predict(X_test_reg)\n",
        "mse_xgb = mean_squared_error(y_test_reg, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test_reg, y_pred_xgb)\n",
        "\n",
        "print(f\"XGBoost Regressor:\")\n",
        "print(f\"  MSE: {mse_xgb:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mse_xgb):.4f}\")\n",
        "print(f\"  R² Score: {r2_xgb:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear Regression\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train_reg_scaled, y_train_reg)\n",
        "\n",
        "y_pred_lr = lr_reg.predict(X_test_reg_scaled)\n",
        "mse_lr = mean_squared_error(y_test_reg, y_pred_lr)\n",
        "r2_lr = r2_score(y_test_reg, y_pred_lr)\n",
        "\n",
        "print(f\"Linear Regression:\")\n",
        "print(f\"  MSE: {mse_lr:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(mse_lr):.4f}\")\n",
        "print(f\"  R² Score: {r2_lr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "models = [('Random Forest', y_pred_rf), ('XGBoost', y_pred_xgb), ('Linear Regression', y_pred_lr)]\n",
        "\n",
        "for idx, (name, y_pred) in enumerate(models):\n",
        "    axes[idx].scatter(y_test_reg, y_pred, alpha=0.5)\n",
        "    axes[idx].plot([y_test_reg.min(), y_test_reg.max()], \n",
        "                   [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
        "    axes[idx].set_xlabel('Actual Valuation ($B)')\n",
        "    axes[idx].set_ylabel('Predicted Valuation ($B)')\n",
        "    axes[idx].set_title(f'{name} - Predictions vs Actual')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/plots/ml_regression_predictions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for Random Forest\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_reg.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance - Random Forest Regressor')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/plots/ml_feature_importance_regression.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Classification: Predict Financial Stage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for classification\n",
        "df_class = df_ml[df_ml['Financial Stage'].notna()].copy()\n",
        "\n",
        "X_class = df_class[feature_cols]\n",
        "y_class = df_class['Financial Stage_encoded']\n",
        "\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_class = StandardScaler()\n",
        "X_train_class_scaled = scaler_class.fit_transform(X_train_class)\n",
        "X_test_class_scaled = scaler_class.transform(X_test_class)\n",
        "\n",
        "print(f\"Training set size: {X_train_class.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_class.shape[0]}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_class))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train_class, y_train_class)\n",
        "\n",
        "y_pred_rf_clf = rf_clf.predict(X_test_class)\n",
        "\n",
        "print(\"Random Forest Classifier:\")\n",
        "print(classification_report(y_test_class, y_pred_rf_clf))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_class, y_pred_rf_clf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost Classifier\n",
        "xgb_clf = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "xgb_clf.fit(X_train_class, y_train_class)\n",
        "\n",
        "y_pred_xgb_clf = xgb_clf.predict(X_test_class)\n",
        "\n",
        "print(\"XGBoost Classifier:\")\n",
        "print(classification_report(y_test_class, y_pred_xgb_clf))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_class, y_pred_xgb_clf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "lr_clf = LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1)\n",
        "lr_clf.fit(X_train_class_scaled, y_train_class)\n",
        "\n",
        "y_pred_lr_clf = lr_clf.predict(X_test_class_scaled)\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(classification_report(y_test_class, y_pred_lr_clf))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_class, y_pred_lr_clf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for classification\n",
        "feature_importance_clf = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_clf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance_clf, x='importance', y='feature')\n",
        "plt.title('Feature Importance - Random Forest Classifier')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/plots/ml_feature_importance_classification.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance_clf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save models\n",
        "joblib.dump(rf_reg, '../../results/models/rf_regressor.pkl')\n",
        "joblib.dump(xgb_reg, '../../results/models/xgb_regressor.pkl')\n",
        "joblib.dump(rf_clf, '../../results/models/rf_classifier.pkl')\n",
        "joblib.dump(xgb_clf, '../../results/models/xgb_classifier.pkl')\n",
        "joblib.dump(scaler_reg, '../../results/models/scaler_reg.pkl')\n",
        "joblib.dump(scaler_class, '../../results/models/scaler_class.pkl')\n",
        "joblib.dump(label_encoders, '../../results/models/label_encoders.pkl')\n",
        "\n",
        "print(\"Models saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
