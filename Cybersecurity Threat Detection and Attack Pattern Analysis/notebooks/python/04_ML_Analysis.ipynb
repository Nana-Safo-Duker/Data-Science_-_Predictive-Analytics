{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis - Cybersecurity Attacks Dataset\n",
    "\n",
    "## Overview\n",
    "This notebook implements multiple machine learning algorithms to classify cybersecurity attacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../../data/Cybersecurity_attacks.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "if '.' in df.columns:\n",
    "    df = df.drop(columns=['.'])\n",
    "\n",
    "# Parse Time column\n",
    "if 'Time' in df.columns:\n",
    "    def parse_time(time_str):\n",
    "        if pd.isna(time_str):\n",
    "            return None, None\n",
    "        try:\n",
    "            if '-' in str(time_str):\n",
    "                start, end = str(time_str).split('-')\n",
    "                return int(start), int(end)\n",
    "            else:\n",
    "                return int(time_str), int(time_str)\n",
    "        except:\n",
    "            return None, None\n",
    "    \n",
    "    time_parsed = df['Time'].apply(parse_time)\n",
    "    df['Time_Start'] = [t[0] for t in time_parsed]\n",
    "    df['Time_End'] = [t[1] for t in time_parsed]\n",
    "    df['Time_Duration'] = df['Time_End'] - df['Time_Start']\n",
    "    df['Datetime_Start'] = pd.to_datetime(df['Time_Start'], unit='s', errors='coerce')\n",
    "    df['Hour'] = df['Datetime_Start'].dt.hour\n",
    "    df['DayOfWeek'] = df['Datetime_Start'].dt.day_name()\n",
    "    df['Month'] = df['Datetime_Start'].dt.month\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "features = ['Source Port', 'Destination Port', 'Hour', 'Month']\n",
    "if 'Time_Duration' in df.columns:\n",
    "    features.append('Time_Duration')\n",
    "\n",
    "# Encode categorical variables\n",
    "le_protocol = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "\n",
    "if 'Protocol' in df.columns:\n",
    "    df['Protocol_encoded'] = le_protocol.fit_transform(df['Protocol'].astype(str))\n",
    "    features.append('Protocol_encoded')\n",
    "\n",
    "if 'DayOfWeek' in df.columns:\n",
    "    day_mapping = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, \n",
    "                   'Friday': 5, 'Saturday': 6, 'Sunday': 7}\n",
    "    df['DayOfWeek_encoded'] = df['DayOfWeek'].map(day_mapping).fillna(0)\n",
    "    features.append('DayOfWeek_encoded')\n",
    "\n",
    "# Target variable\n",
    "if 'Attack category' in df.columns:\n",
    "    df['Attack_category_encoded'] = le_category.fit_transform(df['Attack category'].astype(str))\n",
    "    target = 'Attack_category_encoded'\n",
    "else:\n",
    "    target = None\n",
    "\n",
    "features = [f for f in features if f in df.columns]\n",
    "df[features] = df[features].fillna(df[features].median())\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] if target else None\n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Target classes: {len(le_category.classes_) if target else 0}\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    if name in ['SVM', 'Logistic Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:<20} {result['accuracy']:<12.4f} {result['precision']:<12.4f} \"\n",
    "          f\"{result['recall']:<12.4f} {result['f1']:<12.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['f1'])\n",
    "print(f\"\\nBest Model: {best_model_name} (F1-Score: {results[best_model_name]['f1']:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}